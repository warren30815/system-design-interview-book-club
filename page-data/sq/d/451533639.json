{"data":{"allMdx":{"nodes":[{"fields":{"slug":"/","title":"software-engineering-book-club"},"frontmatter":{"draft":false},"rawBody":"# software-engineering-book-club\n\n## Github pages (Big shout-out to [@ninebird2](https://github.com/ninebird2) for deploying the repo to GitHub Pages!)\n\n<https://warren30815.github.io/software-engineering-book-club/>\n\n## Agenda\n\n[System Design]: ./content/system-design/system-design-interview-alex-xu-volume1/README.md\n[DDD]: ./content/domain-driven-design/domain-modeling-made-functional/README.md\n[Micro Frontend]: ./content/front-end/micro-frontend/README.md\n\n| Date  | Speaker            | Topic               |\n|-------|--------------------|---------------------|\n| 07/07 | Jordan             | [System Design] CH7 |\n| 07/14 | 雷 N               | [System Design] CH6 |\n| 07/21 | 竹子               | [Micro Frontend]    |\n| 07/28 | Jordan             | [System Design] CH8 |\n| 08/04 | Jay / Fienna Liang | [DDD]               |\n\n## Book list\n\nSee content/ folder, including system-design / front-end / domain-driven-design (DDD)... fields.\n"},{"fields":{"slug":"/content/domain-driven-design/domain-modeling-made-functional/","title":"Domain-Modeling-Made-Functional"},"frontmatter":{"draft":false},"rawBody":"English Book on Amazon: [Domain Modeling Made Functional: Tackle Software Complexity with Domain-Driven Design and F# ](https://www.amazon.com/Domain-Modeling-Made-Functional-Domain-Driven/dp/1680502549)\n\n| Chapter                                    | Speaker            | Completed |\n| ------------------------------------------ | ------------------ | --------- |\n| 1. Introducing Domain Driven Design        | Jay / Fienna Liang | ✔️         |\n| 2. Understanding the Domain                |                    | ✔️         |\n| 3. A Functional Architecture               |                    | ✔️         |\n| 4. Understanding Types                     |                    | ✔️         |\n| 5. Domain Modeling with Types              |                    | ✔️         |\n| 6. Integrity and Consistency in the Domain |                    | ✔️         |\n| 7. Modeling Workflows as Pipelines         |                    | ✔️         |\n| 8. Understanding Functions                 |                    | ✔️         |\n| 9. Implementation: Composing a Pipeline    |                    | ✔️         |\n| 10. Implementation: Working with Errors    |                    | ✔️         |\n| 11. Serialization                          |                    | ✔️         |\n| 12. Persistence                            |                    | ✔️         |\n| 13. Evolving a Design and Keeping It Clean |                    | ✔️         |\n\n> Note: Use [Markdown table generator](https://www.tablesgenerator.com/markdown_tables) to load, modify and format the table\n"},{"fields":{"slug":"/content/front-end/micro-frontend/","title":"微前端"},"frontmatter":{"draft":false},"rawBody":"# 微前端\n\n## Defined noun\n\n- 以下均使用 微應用(Micro Application) 替代來稱呼 微前端(Micro Frontend)\n- Module： 每一個 js 檔案都是一個獨立的 Module，多個依賴去進行 import 模組也算一個 Module\n- Package: 宣告了一個 package.json 的多塊 Module 組成的大型模組\n\n## 什麼是 Micro Frontend？\n\n後端微服務來說，就是建立不同的 Service Application 由各自的團隊維護運行。每個團隊使用各自的語言、技術、框架，互不衝突，全部溝通仰賴 HTTP Request & Socket 相互溝通。\n而微前端，則是在一個 SPA (Single Page Application) 之下乘載多個來源的 UI Application 的架構。仰賴使用 Web API 來相互溝通。\n\n## 什麼應用場景需要使用 Micro Frontend？\n\n當前端團隊龐大到一個程度時會產生一些問題：\n\n### 1. 多重技術\n\n要解決的問題：\n不同產品使用不同的前端技術，無法整合\n\n採用後的效用：\n架構可以將兩個不同框架的應用整合成一個。\n\n### 2. 部署\n\n要解決的問題：\n部署要以一個 Application 為單位去打包， bundle 的時間非常久\n\n採用後的效用：\n各個應用也可以單獨部署，無須一整套捆綁在一起，這樣不管是開發還是發布都能減輕負擔\n\n### 3. HMR\n\n要解決的問題：\n架構如果是採用 Webpack 這種工具，當專案變大時，HMR(Hot Module Reload) 會非常久\n\n採用後的效用：\n當啟動應用的必要基礎模組減少變小，那啟動專案和 HMR 所需要的時間就能大幅下降。\n\n### 4. 專案龐大\n\n要解決的問題：\n專案模組巨大，耦合嚴重，單專案應用的學習成本高昂\n\n採用後的效用：\n可以更容易切分工作，能夠把不同的應用和功能切分派給布團的團隊維護。如果剛開始就採用 Micro Application 更能有意識去進行模組的共用切分。\n\n## 實作方法差異產生的優劣分析\n\n目前常見的 Micro Application 解決方案，以及實作範例，但詳細做法不在此處說明。\n\n### Iframe\n\n該方法其實很早以前就被提出，也是最單純的微應用解決方案。\n\n特點：\n\n1. 對於環境隔離性很強，不需要擔心 JS 和 CSS 相互污染。\n2. 學習成本低，容易使用。\n\n缺點：\n\n1. 幾乎無法共用 Module 或 Package，導致一但拆分會異常龐大。\n2. 資料通訊與溝通非常麻煩，幾乎只能靠 postMessage 去通訊。\n\n```jsx\nconst render = () => <iframe src=\"/apps/micro-app.html\" />;\n```\n\n### Client Side JavaScript\n\n透過動態載入 JavaScript Module 來掛載應用，也是目前微應用最主流的作法。\n\n特點：\n\n1. 主程式和為微應用的資料交互容易，也有許多模組共用的解決方案。\n2. 可以共享網頁全域事件和變數。\n\n缺點：\n\n1. 每一個微應用的 js & css 容易相互污染，更甚至會搶用同一個 `window`&`document` 的變數使用\n2. 掛載方式的實作需要關注生命週期與模組載入先後順序\n3. 在 SSR(Server Side Render) 架構下時還要額外實作 SSI\n\n```jsx\nconst mount = async (id) => {\n  const module = await import(\"/apps/micro-app\");\n  const el = document.getElementById(id);\n  const App = module.default;\n  createRoot(el).mount(<App />);\n};\n\nconst render = () => {\n  const id = \"micro-app\";\n  useEffect(() => mount(id), []);\n  return <div id={id}></div>;\n};\n```\n\n### Web Component\n\n特點：\n\n1. 可以使用 shadow dom 去隔離 css\n2. 能夠以開發 Component 為單位去拆分不同的模組，需要注入時只需要用 `customElements.define` 來註冊要追加的元件\n3. 可以不需要關心處理流程，無論先掛載元素還是先讀取 JS 註冊均不影響處理結果，也不會有錯誤發生\n4. 有 SSI 相關解決方案能一併處理 SSR 的問題\n\n缺點：\n\n1. 使用 shadow dom 會產生更多關於 JS 交互的問題，JS 也仍然會交互影響\n2. 初始化時只能取得 attribute 作為參數，無法趕在掛載前將物件參數下傳，需要再重新取出 DOM 實體去傳遞資訊\n\n```jsx\n// remote module\nimport App from \"./App\";\n\nclass MicroApp extends HTMLElement {\n  connectedCallback() {\n    const el = document.createElement(\"div\");\n    this.appendChild(el);\n    createRoot(el).mount(<App />);\n  }\n}\n\ncustomElements.define(\"micro-app\", MicroApp);\n```\n\n```jsx\nconst render = () => {\n  useEffect(() => import(\"/apps/micro-app\"), []);\n  return createElement(\"micro-app\");\n};\n```\n\n## 微前端的缺陷與問題\n\n不管如何，採用這架構背後墊高相當大成本，如果不是超大的產品真的不建議輕易採用。但如果是超大的產品，也會產生要重構並且抽離困難等問題，這就不單純是技術問題。\n\n| -                                    | Front-end monolith                   | Micro frontends                                |\n| ------------------------------------ | ------------------------------------ | ---------------------------------------------- |\n| Codebase (程式碼量)                  | 又大又笨重                           | 分成可管理的模組                               |\n| Deployment (部署)                    | 整個應用同時打包部署                 | 每個模組的獨立部署                             |\n| Feature development speed (開發速度) | 隨著時間的推移減慢                   | 初期架構開發緩慢，但小需求完成快速             |\n| Maintenance (維護)                   | 隨著時間增加更難以維護               | 每個模組維護難度低                             |\n| Stability (穩定)                     | 不足（一個小故障可能會破壞整個系統） | 高（一個組件中的故障對系統影響很小或沒有影響） |\n| Updates (更新)                       | 冗長（可能需要大量程式碼重寫）       | 可以快速推                                     |\n| Tech stack (技術線)                  | 整個系統的技術統一                   | 各個模組可能會有所不同                         |\n| Testing (測試)                       | 隨著時間的推移越難以測試             | 對於單個應用快速，但對於整個完整應用困難       |\n| Team (團隊)                          | 一個團隊維護該專案                   | 多個團隊維護該專案                             |\n| Budget (預算)                        | 取決於項目規模和復雜程度             | 需要大量前期投資                           |\n\n## 微應用實作問題解決方案\n\n在實作微應用時會遇上很多問題，每一種解決方案也都存在對應的優缺點與困難點，甚至有些就是一個大坑，直接是此路不通。因應這些問題，這裡列出各種問題與對應的解決方案。\n以下均是實際在工作上我們採用的架構做為情境來提出解決方案，以這個前提去敘述實作細節。\n\n情境描寫：\n\n- 採用 Web Component\n- 框架： Vue、React\n- 打包工具： Webpack\n\n### Package 共享\n\n問題：\n\n在微應用之中，多個不同的應用會有重複使用的 Package ，這時候就會有共享 Package 的需求。因為每個應用都有自己的打包工具，而且打包工具的版本也不一定相同，這時候就會有版本衝突的問題，而且打包工具的設定也不一定相同，這時候就會有設定衝突的問題。\n\n解決方案：\n\n基於要解決這樣的問題，目前最主流的解決方案就是 `Module Federation`，用來共用模組，還可以做到版本控管的效果。同時也要管理 tree shaking 的問題，避免打包出來的檔案過大。\n\n### CSS 處理\n\n問題：\n\n在微應用之中，CSS 的課題就是全域污染的問題。最重要的就是依據 CSS 採用的方案不同，解決方案也會有所不同。但通常最麻煩的問題是全域使用的 reset CSS & CSS variable ，這時候就會有衝突的問題。而且在微應用之中，CSS 的樣式也會有重複使用的情況，這時候就也會有共享 CSS 的需求。\n\n解決方案：\n\n- 採用 CSS in JS 的方式，這樣就不會有全域污染的問題，但是這樣的方式會有 CSS 語法的限制，而且也會有 CSS 轉換成 JS 的效能問題。\n- 採用 CSS Module 的方式，這樣就不會有全域污染的問題，但對於檔案管理上會多 CSS 相關檔案，打包相關問題比較多。\n- 採用 Atomic CSS 的方式，主軸在每一個微應用都必須遵守一樣的 CSS 規範，這樣就不會有全域污染的問題，但不適合用在技術線不一致的重構整合。\n- 採用 Shadow Dom 強制隔離，但 Shadow Dom 會有 JS 操作限制，對於 querySelector, closest, event bubbling 無法跨越 Shadow Dom。\n\n### 資料交互\n\n問題：\n\n無論整個應用怎麼拆，就是會遇上需要資料交互的需求，這時候就會有資料交互的問題。而且在微應用之中，資料交互的問題就會變得更加複雜，因為每個應用都有自己的狀態管理，這時候就會有狀態管理的問題。\n\n解決方案：\n\n- 使用 CustomEvent，透過 dispatchEvent 來進行資料交互。\n- 使用可以在 global 運作並且廣播狀態變更的狀態管理器，比如 mobx、redux 之類的函式庫。\n- 資料流的管理上會是向上層通知再向下層廣播觸發傳遞，這樣的方式會比較好管理。\n\n### 路由交互\n\n問題：\n\n網頁路由其實只有一個，但在微應用之中，每個應用都有自己的路由，這時候就會有路由交互的問題。\n\n解決方案：\n\n- 每一個框架都有自己的路由管理器，可以透過這些路由管理器來觸發全域事件廣播通知其他的路由進行路由的狀態同步。\n- 也可以乾脆採用單路由管理。\n\n### 多語言處理\n\n問題：\n\n通常每個微應用不但有自己的語系，還會有共享的語系，還可能有外部注入語系，這時候就會有多語言處理的問題。\n\n解決方案：\n\n- 採用 i18n 的方式，每一個微應用建立一個 i18n 實體，各自去管理自己的語言包，避免採用共用。如果有共用需求可以配置權重高底，以外部注入的語系為主，再來是共用語系，最後是自己的語系。\n\n### 部署架構\n\n微應用部署沒有一套標準的解決方案，因為本質就是以 JavaScript 檔案為核心。\n通常會採用的方式有以下幾種：\n\n- 將打包後的靜態黨放在後端的靜態檔案位置，這樣的方式可以避免 CDN 的成本，但是會增加後端管理的負擔。\n- 以 CDN 為主，透過 CDN 來提供檔案，或是放在 MinIO 或 S3 提供靜態檔案。\n- Docker 化，透過 Docker 來提供檔案，這樣的方式可以避免 CDN 的成本，使用 Nginx 來指向到資料位置。\n\n### SSR\n\n問題：\n\n微應用核心概念是使用 JavaScript 動態產生出檔案，但是這樣的方式對於 SEO 來說是非常不友善的，這時候就需要在 Server 完成渲染，但就有不相容問題。也不能直接採用字串渲染，依照現代 SSR 架構其實是 CSR & SSR 混合渲染，如何讓應用知道何時該用 SSR，也知道何時該 CSR。\n\n解決方案：\n\n這個會是微應用上最為麻煩的，基本上建議還是採用 CSR 的方式，但是如果有 SEO 的需求，這時候就需要透過 SSI 的方式來進行渲染。然而 SSI 相關技術目前還不是很成熟，包含 Server Component 的相關函式庫也都不夠穩定，如果還有跨框架的需求，就更加麻煩了。\n透過框架生態系提供的函式庫來進行渲染，或是可以直接用非同步方式取的字串進行截取組合，等到了 CSR 再去取渲染資源來進行渲染。\n\n### 多個 Repo 管理\n\n問題：\n\n因為微應用需要多專案多應用拆分，當要拆分成多個 Repo 管理時，要去相互取用變數、安裝、打包、部署都會比較麻煩，當 Repo 之間的控制與腳本整合就比較不容易。\n\n解決方案：\n\n可以採用 Monorepo 架構，每一個專案各自運行，但部署和共享資訊可以透過 Monorepo 來進行管理。可以使用 Lerna, Nx 等管理工具來進行管理。\n\n### 多種 Framework 管理\n\n問題：\n\n微應用的核心概念就是可以使用不同的框架，但是這樣的方式會有不同框架的相容性問題，而且也會有不同框架的打包問題。\n\n解決方案：\n\n面對不同框架的相容性問題，可以透過 Web Component 來進行管理，但是 Web Component 也會有不同框架的打包問題，這時候就需要透過打包工具來進行管理，但是打包工具也會有不同框架的相容性問題，這時候就需要透過打包工具的插件來整合。微應用與微應用盡量要避免直接傳遞組件物件，盡量使用字串來傳遞，這樣就可以避免不同框架的相容性問題。\n\n## 常見問題\n\n### 直接以 React Component 來進行拆分\n\n或許看過這樣使用 :\n\n```jsx\nconst AppFC = lazy(() => import('app/ReactComponent'))\nfunction App() {\n  return (\n    <Suspense fallback={<div>Loading...</div>}>\n      <AppFC />\n    </Suspense>\n  )\n}\n```\n\n雖然直接以 Component 來進行拆分方方便，但是這樣的方式會當跨框架使用時將無法溝通，這種方式不如採用 Package Library，還可以得到完整的 TS 型別支援，也可以減少網路損耗。而微應用要去解決的應該是業務層的拆分，而不是技術層的拆分。\n\n### 跨應用取得 JS 檔案怎麼取？\n\n應該要把共享元件的進入點封裝成 JS 檔案，而且不要在打算取得的檔案命名的地方加上哈希字串，這樣遠端才能夠預期得到的檔案名稱。或是可以建立檔案索取的路徑表，透過建立資料集查詢索取檔案的目標位置。但這些問題根本解決是需要建立一個 Proxy Server，可以用 Nginx, k8s ingress 等等方案來達到轉址取得靜態資源。不建議直接在前端進行處理，這樣會有安全性的問題。\n\n### 可以使用 Vite Module Federation？\n\n雖然網路上可以找到使用 Vite Module Federation 的範例，但是目前 Vite Module Federation 還不夠穩定，而且也沒有完整的文件，這樣的方式會讓整個專案變得非常不穩定，建議還是使用 Webpack Module Federation，實質上來講，官方也沒有給出很好的解決方案。\n萬一就是要跟 Vite 的專案進行整合，要特別注意有些套件可能發生衝突，甚至沒辦法在 development mode 進行 Module Federation 的跨應用共享。建議的做法是採用 Webpack 執行編譯輸出，隔離開發採用 Vite 運行。但一次兩套維護成本非常高，目前只期待官方能夠提供更好的解決方案，尚無較優的解決方案。\n舉例像是靜態資源路徑並未優化，要手動再去處理路徑。也沒有提供像是 webpack 有多種載入機制，目前只提供 script module 一種。\n\n### 前端變數該怎麼傳遞？\n\n大部分前端想渲染變數，直覺做法其實是在專案 env 設定，但這其實是有很大的限制。如果需要在 Docker Image 環境渲染就會無法修改，每一次修改變數就要經歷漫長的 docker build 過程。最理想是要有一個變數的靜態檔案存放在資源處，透過修改這份靜態檔案，讓重新拉取應用的對象或是直接在部署階段都可以帶入參數。這樣的方式可以避免每一次修改變數都要重新打包，也可以避免在 Docker Image 環境無法修改變數的問題。\n如果提供資源的主應用能夠採用 Client Service，更能夠動態透過伺服器去渲染變數。當然，SSR 架構的微應用更加複雜。\n\n### 要如何共享型別和函式？\n\n答案是「不要共享」，所有要共享的東西應該都包裝成 Package Library，要傳遞的狀態則是透過傳遞用的接口去接收，型別則是透過 Package Library 去得知，或是以規範文件去規定應該使用的規格。\n\n### 要如何共享靜態資源？\n\n在使用 vite 打包會遇上靜態路徑資源會吃遠端對象的問題，最好的解決方案就是使用將相關靜態資源包上 CDN。或是將所有靜態資源以 JS 的形式封裝用 JS 的方式進行載入，可以避開既有機制上的限制。\n\n## Reference\n\n- [Micro Frontends](https://leanylabs.com/blog/micro-frontends-overview/)\n- [All You Need to Know About Micro Frontends](https://micro-frontends.org/)\n"},{"fields":{"slug":"/content/system-design/system-design-interview-alex-xu-volume1/","title":"System-Design-Interview-Alex-Xu-Volume1"},"frontmatter":{"draft":false},"rawBody":"English Book: [System Design Interview – An insider's guide: Xu, Alex (Volume 1)](<https://github.com/G33kzD3n/Catalogue/blob/master/System%20Design%20Interview%20An%20Insider%E2%80%99s%20Guide%20by%20Alex%20Xu%20(z-lib.org).pdf>)\n\nChinese Translation: [內行人才知道的系統設計面試指南](https://www.books.com.tw/products/0010903454)\n\n| Chapter                                                        | Speaker            | Completed |\n| -------------------------------------------------------------- | ------------------ | --------- |\n| CHAPTER 1: SCALE FROM ZERO TO MILLIONS OF USERS                | Jay / Fienna Liang | ✅        |\n| CHAPTER 2: BACK-OF-THE-ENVELOPE ESTIMATION                     |                    | ✔️        |\n| CHAPTER 3: A FRAMEWORK FOR SYSTEM DESIGN INTERVIEWS            |                    | ✔️        |\n| CHAPTER 4: DESIGN A RATE LIMITER                               | 杯 / 雷 N          | ✅        |\n| CHAPTER 5: DESIGN CONSISTENT HASHING                           | 雷 N               | ✔️        |\n| CHAPTER 6: DESIGN A KEY-VALUE STORE                            | 雷 N               | ✔️        |\n| CHAPTER 7: DESIGN A UNIQUE ID GENERATOR IN DISTRIBUTED SYSTEMS | Jordan             | ✔️        |\n| CHAPTER 8: DESIGN A URL SHORTENER                              | Jordan             | ✔️        |\n| CHAPTER 9: DESIGN A WEB CRAWLER                                | Jordan             | ✔️        |\n| CHAPTER 10: DESIGN A NOTIFICATION SYSTEM                       | 雷 N               | ✔️        |\n| CHAPTER 11: DESIGN A NEWS FEED SYSTEM                          |                    | ✔️        |\n| CHAPTER 12: DESIGN A CHAT SYSTEM                               |                    | ✔️        |\n| CHAPTER 13: DESIGN A SEARCH AUTOCOMPLETE SYSTEM                |                    | ✔️        |\n| CHAPTER 14: DESIGN YOUTUBE                                     | Jordan             | ✔️        |\n| CHAPTER 15: DESIGN GOOGLE DRIVE                                |                    | ✔️        |\n| CHAPTER 16: THE LEARNING CONTINUES                             |                    | ✔️        |\n\n> Note: Use [Markdown table generator](https://www.tablesgenerator.com/markdown_tables) to load, modify and format the table\n\n<img width=\"371\" alt=\"截圖 2023-06-05 上午10 22 08\" src=\"https://github.com/warren30815/system-design-interview-book-club/assets/36834814/c634e1e9-f1e3-46af-95b6-1ae14bc3887a\" />\n"},{"fields":{"slug":"/content/system-design/system-design-interview-alex-xu-volume1/chapter-1/chapter_1/","title":"第一章：使用者人數 -- 從零到百萬規模"},"frontmatter":{"draft":false},"rawBody":"# 第一章：使用者人數 -- 從零到百萬規模\n\n此篇主要在講最簡單的單台主機設置，到百萬規模的系統，中間如何逐步加入各個元件，以及每個元件如何擴展。\n經過第一章的介紹，便可以對一個可規模化 (scalable) 的系統有相對完整與綜觀的認識。\n\n## 單台主機\n\n關鍵元件：\n\n1. Client (web, mobile)\n2. DNS server\n3. Web server\n\n主要流程：\n\n1. 客戶端發起請求\n2. DNS 伺服器解析出網站伺服器 IP\n3. 網站伺服器處理流量\n\n## 資料庫\n\n關鍵元件：\n\n1. Client (web, mobile)\n2. DNS server\n3. Web server\n4. Database\n\n主要流程：\n\n1. 客戶端發起請求\n2. DNS 伺服器解析出網站伺服器 IP\n3. 網站伺服器處理流量\n4. 網站伺服器向資料庫請求資料，或送出資料修改請求\n\n資料庫型態：\n\n1. 關聯式資料庫 (RDBMS)\n2. 非關聯式資料庫 (NoSQL)\n   1. CouchDB\n   2. Cassandra\n   3. Hbase\n   4. AWS DynamoDB\n\n## 擴展\n\n1. 垂直擴展：加大機器的 CPU, memory, disk 等硬體處理能力。但存在以下問題：\n   1. 一台機器的運算與儲存擴展有硬體上的極限\n   2. 會造成單點故障 (single point of failure), 即系統的單一節點故障便導致整個系統變得不可用\n2. 水平擴展：增加更多台機器。能夠解決以上問題，也是在討論擴展時的主要對策。\n\n## 負載平衡 (Load Balancer)\n\n關鍵元件：\n\n1. Client (web, mobile)\n2. DNS server\n3. *Load Balancer*\n4. Web server\n5. Database\n\n主要流程：\n\n1. 客戶端發起請求\n2. DNS 伺服器解析出網站伺服器 IP\n3. *負載平衡接收流量後往後面多台機器分配請求*\n4. 多台網站伺服器處理流量\n5. 網站伺服器向資料庫請求資料，或送出資料修改請求\n\n解決的問題\n\n1. 可透過增加網頁伺服器數量來處理更多的請求，解決了擴展性的問題 (scalability)\n2. 當有一台機器故障時，負載平衡器可以將請求發送至其他運作中的機器，增加了可用性 (availability)\n\n注意事項：\n\n1. 由於資安因素，通常網頁伺服器會透過內網通訊，只有負載平衡器連接外網\n2. 負載平衡器可能變成系統中單點故障所在，但可使用 DNS server 的循環解析 (Round-robin DNS resolution) 或其他方式來解決單點故障問題\n\n## 資料庫複製 (Database Replication)\n\n關鍵元件：\n\n1. Client (web, mobile)\n2. DNS server\n3. Load Balancer\n4. Web server\n5. *Database with multiple replica*\n\n主要流程：\n\n1. 客戶端發起請求\n2. DNS 伺服器解析出網站伺服器 IP\n3. 負載平衡接收流量後往後面多台機器分配請求\n4. 多台網站伺服器處理流量\n5. 網站伺服器向資料庫請求資料，或送出資料修改請求\n6. *資料庫主節點(master)負責處理寫入與讀取，從節點(slave)負責處理讀取請求*\n\n解決的問題\n\n1. 當讀取資料的請求很多時，從節點可分攤讀取請求，並且可透過增加從節點來達成擴展\n2. 資料備份：即使有節點損毀，依然能保證可以從其他節點獲得完整的數據\n\n## 快取 (Cache)\n\n關鍵元件：\n\n1. Client (web, mobile)\n2. DNS server\n3. Load Balancer\n4. Web server\n5. *Cache*\n6. Database with multiple replica\n\n主要流程：\n\n1. 客戶端發起請求\n2. DNS 伺服器解析出網站伺服器 IP\n3. 負載平衡接收流量後往後面多台機器分配請求\n4. 多台網站伺服器處理流量\n5. 網站伺服器向*快取*請求資料，或送出資料修改請求\n6. *快取負責暫時性儲存資料，回應伺服器需求*\n7. 資料庫主節點(master)負責處理寫入與讀取，從節點(slave)負責處理讀取請求\n\n注意事項\n\n1. 使用快取最需要關注的問題是決定何時資料是失效的，可能的方法有\n   1. 快取壽命 (Time to live, TTL)：快取資料經過特定時間長度後即視為無效\n   2. Read-through：快取接收到請求時判別有沒有資料，有就回傳，沒有的話從資料庫拿取，回應請求，並貯存在快取中\n   3. Write-through：服務接收到寫入請求時，同時往快取與資料庫寫入資料，以保證資料都是最新的。缺點是兩邊都要寫入可能導致回應時間變長\n2. 快取滿了的時候的處理方式\n   1. LRU (Least-recently-used)：上次被使用時間距今最久的先清掉\n   2. LFU (Least-frequently-used)：最不常使用到的先清掉\n   3. FIFO (First-in-first-out)：先進來的先清掉\n\n## 內容傳遞網路 (Content Delivery Network, CDN)\n\n關鍵元件：\n\n1. Client (web, mobile)\n2. *CDN*\n3. DNS server\n4. Load Balancer\n5. Web server\n6. Cache\n7. Database with multiple replica\n\n主要流程：\n\n1. 客戶端發起請求\n2. *對於靜態資料如圖片或指令碼，CDN 能夠直接回應請求，減少系統負擔*\n3. DNS 伺服器解析出網站伺服器 IP\n4. 負載平衡接收流量後往後面多台機器分配請求\n5. 多台網站伺服器處理流量\n6. 網站伺服器向快取請求資料，或送出資料修改請求\n7. 快取負責暫時性儲存資料，回應伺服器需求\n8. 資料庫主節點(master)負責處理寫入與讀取，從節點(slave)負責處理讀取請求\n\n注意事項：\n\n1. CDN 通常在全球分佈，接收並處理地理距離上較近的請求，以減少回應時間\n2. CDN 也要注意如何使資料無效 (invalidation)，常見的方法有\n   1. TTL：經過一定時間後資料無效\n   2. 版本：在 URL 攜帶版本號，因此當客戶端請求不同版本時，CDN 便會向伺服器詢問最新版的資料\n\n## 伺服器狀態 (Stateful vs Stateless)\n\n### Stateful\n\n伺服器會將使用者資料貯存在同個伺服器上，例如將會話 (session) 存在機器上\n\n問題：當水平擴展時，如果使用者的請求被負載平衡器分配到不同的機器上，則該機器沒有使用者的會話資料，將導致系統出現預期外的行為\n\n### Stateless\n\n伺服器將所有的資料貯存在第三方元件或系統中，而非自身的貯存空間\n\n伺服器在處理請求時，可以把每個請求看成獨立的流程來處理，不需要考慮當下請求跟之前的請求有沒有關聯，也不需要考慮該請求所需要的資訊是否存在自己的貯存空間中\n\n可用的會話資料處存方案：\n1. Memcached\n2. Redis\n3. NoSQL\n\n備注：\n1. 在討論水平擴展時，通常假設伺服器是無狀態的，這樣在部署時就不需要考慮負載平衡器該如何解決前後請求之間的關係\n2. 即使如此，一些負載平衡器還是可以提供所謂\"親和性\"的機制 (affinity)，例如將來自同一個 IP 的請求都分配到同一台機器上\n\n## 資料中心 (Data Centers)\n\n關鍵元件：\n\n1. Client (web, mobile)\n2. CDN\n3. DNS server\n4. Load Balancer\n5. *Web server in multiple data centers*\n6. Cache\n7. Database with multiple replica\n\n主要流程：\n\n1. 客戶端發起請求\n2. 對於靜態資料如圖片或指令碼，CDN 能夠直接回應請求，減少系統負擔\n3. DNS 伺服器解析出網站伺服器 IP\n4. 負載平衡接收流量後往後面多台機器分配請求\n5. *多台網站伺服器分布在不同的資料中心中處理流量*\n6. 網站伺服器向快取請求資料，或送出資料修改請求\n7. 快取負責暫時性儲存資料，回應伺服器需求\n8. 資料庫主節點(master)負責處理寫入與讀取，從節點(slave)負責處理讀取請求\n\n注意事項：\n\n1. DNS 通常會根據使用者的地理位置來解析請求，回應請求一個距離使用者較近的資料中心\n2. 這裡雖然用的名稱是 Data Center, 但我認為用 AWS 的 Availability Zone 來說明會更好解釋。即不同的資料中心是在地理距離上分佈相距較遠的，如此一來可以在某區域發生災害時依舊保證有其他地理區域的資料中心依舊可用。例如當 ap-northeast-1 (東京) 的資料中心所在區域發生地震時而導致資料中心不可用時，us-east-2 依舊可用，不會因為地理位置相近而導致所有資料中心同時損毀。\n\n## 訊息隊列 (Message Queue)\n\n關鍵元件：\n\n1. Client (web, mobile)\n2. CDN\n3. DNS server\n4. Load Balancer\n5. Web server in multiple data centers\n6. *Message Queue*\n7. *Workers*\n8. Cache\n9. Database with multiple replica\n\n主要流程：\n\n1. 客戶端發起請求\n2. 對於靜態資料如圖片或指令碼，CDN 能夠直接回應請求，減少系統負擔\n3. DNS 伺服器解析出網站伺服器 IP\n4. 負載平衡接收流量後往後面多台機器分配請求\n5. 多台網站伺服器分布在不同的資料中心中處理流量\n6. 網站伺服器向快取請求資料，或送出資料修改請求。*長時間操作則將資訊送往訊息隊列*\n7. *Worker 接受隊列內的消息並逐一處理*\n8. 快取負責暫時性儲存資料，回應伺服器需求\n9. 資料庫主節點(master)負責處理寫入與讀取，從節點(slave)負責處理讀取請求\n\n注意事項\n\n1. Queue 只是這邊提到的一種方式，其他的訊息溝通系統還包含生產-訂閱 (Pub/Sub) 等機制。\n2. 費時較長且不需要使用者立即得知結果的操作，設計上通常不會由網站伺服器處理，這時就可以讓網站伺服器把這類工作打包成訊息，丟到隊列中，並且由特定的工作伺服器 (worker) 去消化隊列訊息，並異步處理。\n3. 常見的應用情境包含：寄信、影像處理、資料分析。\n4. Queue 的作用還包含服務之間的*去耦合*，即讓接收訊息與處理訊息者不需要了解彼此的部署與實作，並且兩者可以實現不同的擴展策略。\n\n## 日誌、指標、自動化 (Logging, Metrics, Automation)\n\n- 日誌：對於了解服務哪裡出錯以及獲取除錯所需的資訊來說至關重要\n- 指標：了解服務的關鍵資訊，例如回應時間、系統負載、使用者數量、關鍵業務請求數量等\n- 自動化：使用 CI/CD 等手段確保即使系統成長的更加複雜，大量事務能夠被自動化處理，服務能持續運行\n\n## 資料庫水平擴展\n\n擴展方法：\n\n1. 垂直擴展：加大機器處理與貯存的運算能力\n2. 水平擴展：分片 (Sharding)\n\n注意事項\n\n1. 分片需注意使用什麼欄位作為 Sharding key，要避免資料集中在一個分片上\n2. 若要重新分片資料時會是個複雜的挑戰\n3. 名人問題：大量讀取可能都是針對少部分資料，導致特定分片承受大量流量，而其他分片則閒置\n4. 分片會使得要做 join 等聚合操作時變得困難，這些邏輯可能需要在應用層完成\n5. 資料庫擴展方法有很多，這裡提到的主從式架構 Master-slave 只是其中一種，其他還有包含\n   1. Multi-master\n   2. Consistent Hashing\n   3. Partitioning\n   4. Distributed Transaction\n   5. Command Query Responsibility Segregation\n"},{"fields":{"slug":"/content/system-design/system-design-interview-alex-xu-volume1/chapter-4/chapter_4/","title":"第四章：設計網路限速器"},"frontmatter":{"draft":false},"rawBody":"# 第四章：設計網路限速器\n\n## # 主軸\n\n- 主要在 Layer 7: Application layer\n\n- 作用：\n\n  - 防止 DoS: 避免資源餓死 (resouce starvation)\n  - 節省流量成本: 流程內可能會調用到第三方服務 (依次計費), 或者 LB 依請求次數計費, 如果能在避免資源餓死的前提下作考量時, 那麼大部分的請求被拒絕時, 自然而然以上的成本會下降\n  - 防止超載: 會打請求的未必只是人還有Bot, 為了避免大家把有限資源的服務器打暴為前提做設計 (更多能參考SLA)\n\n- 目標：\n\n  - server-side API rate limiter\n\n    - REF: client: axios-rate-limit: other will be delayed automatically.\n\n  - a large number of requests --> Low latency & little memory？\n \n  - 聚合用的欄位, 希望足夠彈性\n\n  - exception handling, inform users\n\n  - service (API Gateway) vs server-side code\n\n  - work in distributed environment, 在這裡指的是 Rate limiter 本身可能不只是 cluster, 甚至跨 VPC, 跨 AZ 的環境\n\n  - high fault tolerance: Rate limiter 本身非業務流程上的必要功能, 它本身的好壞不該影響到整個系統, 因此考量時, 該怎設計隔離 rate limte service 某個節點異常的部份\n \n  - low latency: rate limit本身非業務所需功能, 不應該在latency上佔比過高\n\n  - technology stack\n\n  - algorithm 可選性\n\n  - 時間成本\n\n## # Algorithm\n\n- 演算法介紹\n\n  - Token bucket\n\n  - Leaking bucket\n\n  - Fixed window counter\n\n  - Sliding window log\n\n    - 可在每次收到請求時，才清除舊資料。安排固定時間或長度清除\n    \n    Q: 為什麼連被拒絕的請求也要加入 log 做計數？\n    \n    A: 這個的設計其實不是為了直接給 rate limiter 來計算用的，而是其他需求，畢竟叫做 log，像 nginx access log 一樣，有請求來的本來就都會被紀錄，有以下四個常見需求：\n    \n       1. 故障排查用: 被拒絕的請求可能表示系統中存在問題。例如，如果出現許多請求被拒絕，可能意味著系統超負荷、有 bug、或者資源分配不足。透過記錄被拒絕的請求，工程師能夠回溯問題並進行修復。\n       2. 監控系統負載: 大量的被拒絕的請求可能表示系統負載過高或者資源短缺。這些日誌可以作為我們監控系統狀態和評估資源需求的依據。\n       3. 離線用戶行為分析: 對於被拒絕的請求進行記錄和分析，可以幫助我們更好地了解用戶的行為模式，以及那些功能或服務可能存在問題。然後我們就可以對這些問題進行調整和優化。\n       4. 法規和合規需求: 在某些情況下，法規可能要求我們記錄所有的請求，包括被拒絕的請求。\n    \n    ref: [Rate limiting - why log rejected requests' timestamps in Sliding window log algorithm?](https://www.reddit.com/r/AskComputerScience/comments/xktn2j/rate_limiting_why_log_rejected_requests/)\n\n  - Sliding window counter\n\n- 演算法比較\n\n  - Bucket vs Window\n\n    - 可看作 Bucket 可以把可接受的峰值跟均速分開設定，Window 把峰值跟均速綁在一起\n    - 因此 Bucket 需要調整兩個參數達到平衡，也相對較困難\n\n  - Bucket\n\n    - A. Token bucket\n\n      - 適合處理瞬間流量，如搶購\n      - 比 B 更有效的利用資源\n\n    - B. Leaking bucket\n\n      - 穩定輸出模型\n      - 不適合瞬間流量，如搶購。因為即使流量在可接受範圍，依然會按照一個速率進行\n\n  - Window\n\n    - C. Fixed window counter\n\n      - 可能會有時間差聚集現象，實質上超過流量\n\n    - D. Sliding window log\n\n      - 解決 C 的問題，一定不會超過流量限制\n      - 大量耗費記憶體，因為須記錄所有 timestamp\n      - 清除舊資料很耗時\n\n    - E. Sliding window counter\n\n      - 解決 D 的記憶體使用問題，但保有大概率解決 C 的問題，不會超過流量\n      - 實驗統計只有 0.003% 出錯\n\n## # High-level architecture\n\n## # Design deep dive\n\n- Rate limiting rules 怎被建立、儲存、存取和更新: 依照結構化格式(YAML, JSON, XML...)，將規則的欄位給格式化\n\n- Exceeding the rate limit\n\n  - HTTP 429 (Too many requests)\n\n    - 放到待處理\n    - 直接捨棄\n\n  - Rate limiter headers\n\n    - 沒超過限制\n\n      - X-Ratelimit-Remaining: 在時間區間內還剩下多少配額\n      - X-Ratelimit-Limit: 在時間區間內，客戶端請求的限額\n      - X-Rate-Limit-Reset: 一個代表時間的數值，時間到將重設配額\n\n    - 超過限制回傳 429\n\n      - X-Ratelimit-Retry-After: 指定客戶端在傳送下一個要求之前所應等待 (或睡眠) 的秒數。如果重試值沒過就傳送要求，則不會處理要求，並且會回傳新的重試值。\n     \n      **Client需要知道這些資訊，才好控制下一次發出請求 (甚至也能說是一種Retry policy的控制)**\n\n- Detailed design\n\n  Q: 這些資訊適合存放在哪？\n  \n  A: RDBMS太慢且本身的資料結構也不適合存放大量數據，且有熱點存取問題，因此選擇 in memory store 是適合的，夠快且過期的資料通常 in-memory db 有配合的機制能汰除掉，因為我們這裡大部分都只要計次 (sliding window log 例外)，Redis有提供INCR與EXPIRE (甚至TTL機制)，便於使用\n\n- Rate limiter in a distributed environments\n\n  - Race condition (類似超賣問題)\n\n    - Locks\n\n      - 會降低效能，吞吐量會受影響\n\n    - Lua script\n\n      - 因為是「原子性的」\n      - 因為 lock 是對資源層級的鎖定，靈活性較低，以原子性的腳本來做，能夠只在需要的步驟上使用\n\n    - sorted sets data structure\n\n      - [Skip List](https://mecha-mind.medium.com/redis-sorted-sets-and-skip-lists-4f849d188a33)\n\n  - Synchronization issue\n \n    在跨 VPC / AZ 的情況下，很可能 rate limiter 內的資訊與狀態不一致，對同一個user，不同請求會隨機跳轉到不同 rate limiter 上被處理，那就等於白搭了，所以在這裡會建議用同一個 redis cluster，以及啟用 sticky session機制，讓同一個 user 的不同請求都能在同一個 rate limiter 上被處理\n\n    - sticky sessions\n\n      - 讓 client 去固定 rate limiter，不彈性不好擴展\n\n    - centralized data stores\n\n      - REF: [A Comprehensive Guide to Distributed Caching](https://blog.devgenius.io/a-comprehensive-guide-to-distributed-caching-827f1fa5a184)\n\n- Performance optimization\n\n  - multi-data center\n  - eventual consistency model\n    - 相較於完全一致性更有效率，但又保有一致性\n    - chaper 6\n\n- Monitoring\n\n  - 需監控以下兩個面向是否能有效地達到目的\n\n    - rate limiting rules\n    - rate limiting algorithm\n      - EX. flash sales --> Token bucket\n\n## # 延伸討論\n\n- 不同 layer 的防範\n\n  - 在 layer 3 進行較快？\n  - 全公司同一個 ip\n  - 沒登入時 (也可在 layer 7 用 session)\n  - 針對不同類型使用者，不同策略\n  - 不同 layer 的防範，不是選擇，而是一起用，各自防不同面向。但用太多會不會影響到單次請求的效能？\n\n- 加強 client，避免問題\n\n  - client cache\n  - 合理的發送請求？\n  - catch exceptions or errors\n  - back off time：可用指數型成長策略\n\n- Hard vs Soft\n\n  - Hard rate limiting\n\n    - 超過限制的請求將被直接拒絕或返回錯誤\n    - 確保系統在特定時間內不會超過預定的請求速率\n    - 可能導致客戶端體驗不佳\n\n  - Soft rate limiting\n\n    - 允許短期內超過限制的請求，但在長期內維持平均速率不超過預定的限制\n    - 通常使用 Bucket 演算法\n\n- 當服務器「總負載」快要超出限額，會怎麼做？\n\n  - 平均調低 rate limit threshold\n  - 把流量留給重要的請求或用戶\n  - 大家都暫停別用\n  - 機器開下去\n  - 其他\n\n- Circuit breaking（熔斷）和 degradation（降級）\n"},{"fields":{"slug":"/content/system-design/system-design-interview-alex-xu-volume1/chapter-7/chapter_7/","title":"第七章：設計可用於分散式系統的唯一 ID 生成器"},"frontmatter":{"draft":false},"rawBody":"# 第七章：設計可用於分散式系統的唯一 ID 生成器\n\n## 前言\n\n唯一 ID 在系統中很重要，在單資料庫伺服器中，可以利用 primary key + _auto_increment_ 屬性來實作唯一 ID，但在分散式系統中，有多資料庫伺服器間的同步問題，本篇會介紹四種方法，以及各自的優缺點及使用時機\n\n## 步驟一：需求範圍確認\n\nQ: 唯一 ID 須具備哪些性質\n\nA: 須為唯一且可依時間先後排序\n\nQ: 新生成的 ID，是否為上一個 ID + 1\n\nA: ID 需隨時間嚴格遞增，但不一定需要絕對差距 1\n\nQ: ID 是否全為數字，還是可以有文字\n\nA: 需全為數字\n\nQ: ID 的長度有限制嗎\n\nA: 需為 64 bits\n\nQ: 系統的規模有多大\n\nA: 每秒需要能產生 10,000 IDs\n\n## 步驟二：high-level 架構\n\n四種分散式系統中唯一 ID 的設計方法：\n\n1. Multi-master replication\n2. Universally unique identifier (UUID)\n3. Ticket server\n4. Twitter snowflake approach\n\n### Multi-master replication\n\n![](assets/multi_master.png)\n\n如圖，還是利用資料庫的 _auto_increment_ 功能，只是不是 + 1，而是比如有 k 個資料庫就 + k，圖中 k = 2\n\n缺點：\n\n1. 多個資料中心下很難擴充\n2. ID 的值不一定隨著時間嚴格遞增，比如有一台產生較多，一台產生較少，那後者產生出的 ID 數值即使生成時間較晚，但 ID 數值仍會小於前者生成較早的 ID\n3. 很難 auto-scale 伺服器\n4. 離線時無法使用\n\n### UUID（Universally Unique Identifier）\n\nUUID 是一個能產生 128 bits ID 的演算法，有著極小的碰撞概率，每秒產生 10 億個 UUID 的情況下持續 100 年，只有 50% 的機率會碰撞\n\n一個 UUID 的範例：_09c93e62-50b4-468d-bf8a-c07e1040bfb2_，32 個 16 進位的字元，所以為 128 bits (32 \\* 4)\n\n因為有著極低的碰撞概率，因此可以每個伺服器都跑自己的 UUID 生成器，如下圖：\n\n![](assets/uuid.png)\n\n註：uuid 演算法\n\n---\n\n分成 v1 ～ v5，根據 uuid.js 統計有 77% 使用者選擇 v4；21% 使用者選擇 v1，有特殊需求才會選 v5 & v3，v2 基本上不採用 ([ref1](https://yuanchieh.page/posts/2020/2020-12-01-uuid-%E5%8E%9F%E7%90%86%E8%88%87%E5%AF%A6%E4%BD%9C%E5%88%86%E6%9E%90-%E8%A9%B2%E5%A6%82%E4%BD%95%E6%8C%91%E9%81%B8%E9%81%A9%E5%90%88%E7%9A%84-uuid-%E7%89%88%E6%9C%AC/))，使用時機可大略分為 ([ref2](https://stackoverflow.com/questions/20342058/which-uuid-version-to-use)、[ref3](https://www.uuidtools.com/uuid-versions-explained))：\n\n_只是單純需要一個隨機不重複的 uuid_：v4，會從超過 5.3 x 10^36 種可能的 uuid 裡面隨機生成出一個，分為兩個變化版，variant-1 為 Minecraft 中使用的演算法；variant-2 即 Microsoft 系統內的 GUID [ref3]\n\n_需要在前者的基礎上知道時間資訊（精度到 100 nanoseconds）和是哪台機器產生的_：v1，格式見下圖，前三組為時間資訊，表示從 1582-10-15 00:00:00 到現在經過了多少個 100 ns ([ref4](https://stackoverflow.com/questions/3795554/extract-the-time-from-a-uuid-v1-in-python))，low time 代表算出的間隔的最後 32 bits；mid time 為中間 16 bits；第三項為版本資訊 + 開頭 16 bits；第四項為 variant 編號 + system clock 值；第五項為網卡的 mac address\n\n![](assets/uuid_v1.png)\n\n要 decode 出時間的話，可參考該 python code ([ref5](https://stackoverflow.com/questions/17571100/how-to-extract-timestamp-from-uuid-v1-timeuuid-using-javascript)):\n\n![](assets/uuid_v1_decode.png)\n\n_需要能根據 namespace + input 產生 reproducible 的 uuid_：用 v3 或 v5，v3 將 input 用 MD5 hash；v5 用 SHA-1 hash，所以 v5 較 v3 安全\n\nnamespace 可以視為你的 key 的概念，範例可見 [ref6](https://stackoverflow.com/questions/10867405/generating-v5-uuid-what-is-name-and-namespace)\n\nRecap ([ref6](https://stackoverflow.com/questions/10867405/generating-v5-uuid-what-is-name-and-namespace))\n\n![](assets/uuid_recap.png)\n\n---\n\n優點：\n\n1. 簡單，不用考慮伺服器間的同步問題，且離線時也能使用\n2. 承上，高擴展性\n\n缺點：\n\n1. 128 bits 太長，浪費空間且不符合一開始的需求（64 bits）\n2. ID 不隨著時間嚴格遞增\n3. ID 內有非數字的值，不符合一開始的需求（需全為數字）\n\n### Ticket Server\n\n![](assets/ticket_server.png)\n\n如圖，ID 的發放統一由ㄧ伺服器負責\n\n優點：\n\n1. 可達成 ID 需為全數字的需求\n2. 容易實作，適用於小至中型系統\n\n缺點：\n\n1. Single point of failure\n2. 離線時無法使用\n\n### Twitter snowflake approach\n\n![](assets/snowflake.png)\n\n將 64 bits 分成幾個區塊，有點像是網路封包 header 的做法\n\n- 符號 bit：1 bit，二進位中 0 代表正，1 代表負\n\n- 時間戳記：41 bits，將毫秒等級的 unix timestamp 轉為二進位，此方式可用到 2039 年 41 bits 才會不夠用\n\n- 資料中心 ID：5 bits，上限 2 ^ 5 = 32 個資料中心\n\n- 機器 ID：5 bits，一個資料中心上限 2 ^ 5 = 32 台機器\n\n- 流水號：12 bits，為了處理高併發狀況，一毫秒內（因上面時間戳記的精度是毫秒）可能會同時產生一堆 UUID，因此一毫秒內產生的不同 UUID，流水號會以 + 1 的方式區分，此欄位每毫秒會重置\n\n## 步驟三：深入探討\n\n由上可知，最符合需求的是 Twitter snowflake approach，因此我們來探討其相關細節\n\n- 符號 bit：正常情況 ID 為正數，因此基本上此 bit 都為 0\n\n- 時間戳記：上述有提到到 2039 年 41 bits 會不夠用，因此 twitter 實務上此欄位的時間是為距公司創立時經過的相對時間，如下圖：\n\n![](assets/twitter_time.png)\n\n- 資料中心 ID：基本上不會用到這麼多資料中心，因此可減少 bit 數給其他人用，或者只有單一個資料中心的情況下，可替換為 table 的編號\n\n- 機器 ID：同上，隨著自身業務情況調整 bit 數\n\n- 流水號：用了 12 bits，每毫秒可產生 2 ^ 12 = 4096 個 UUID，需求為每秒 10,000 個 UUID 而已，因此這部分的 bits 數也可以考慮挪點給別人用\n\n## 步驟四：總結\n\n延伸可討論的點：\n\n- Clock synchronization：不同的機器的 system clock 不一定會對齊，因此實務上的解法是都跟 NTP 伺服器對時\n\n- Section length tuning：如上討論過的，snowflake 方法每個欄位需要多少 bit 的取捨，減少流水號欄位的 bit 用量而多分配給 timestamp 欄位，雖會降低併發能力，但能延後時間 overflow\n\n- High availability：ID 生成器很重要，設計上需考慮好如何保證高 availability\n\n## 補充資料\n\n一個簡單生成可排序的分散式 global uuid 演算法 [xid](https://github.com/rs/xid)\n\n一個 xid 的範例：_9m4e2mr0ui3e8a215n4g_，可以看到比 UUID 簡潔多了（雖然時間精度只到秒）\n\n其是基於 Mongo Object ID algorithm 生成的字串，Mongo Object ID 基本上格式如下：\n\n```\n0|1|2|3     4|5|6    7|8|      9|10|11\n\nTimestamp  machine   PID   Increment counter\n```\n\n再經由 base32hex (base32 的 variant 版本) 來去把它編碼成更短的字串（24 vs 20 hexadecimal digits）([ref](https://github.com/rs/xid/blob/master/README.md))\n\n![](assets/xid.png)\n\n![](assets/xid_note.png)\n\n![](assets/benchmark.png)\n"},{"fields":{"slug":"/content/system-design/system-design-interview-alex-xu-volume1/chapter-8/chapter_8/","title":"第八章：設計短網址生成器"},"frontmatter":{"draft":false},"rawBody":"# 第八章：設計短網址生成器\n\n## 前言\n\n本篇會介紹如何設計一短網址生成器，主要探討 hash 映射函數的設計（for URL shortening）以及從短網址拿到完整網址後的 URL 重導向（redirecting）\n\n## 步驟一：需求範圍確認\n\nQ: 可以舉個例子說明此短網址服務的運作嗎\n\nA: 假設 https://www.systeminterview.com/q=chatsystem&c=loggedin&v=v3&l=long 為原始網址，此服務會創建一縮短版本（alias），如 https://tinyurl.com/y7keocwj ，如點擊此 alias，會將你重導向至原始網址\n\nQ: 服務要支援多大流量規模\n\nA: 每天 100 million 個網址\n\nQ: 短網址長度是否有限制\n\nA: 越短越好\n\nQ: 生成的短網址是否有符號限制\n\nA: 需全為數字或英文（0-9 & a-z & A-Z）\n\nQ: 短網址是否可被刪除或更新\n\nA: 可假設不會被刪除或更新\n\n### 需求總結\n\n1. URL shortening：給一長網址 -> 回傳短網址\n2. URL redirecting：給一短網址 -> 回傳長網址並重導向\n3. 高可用性、擴展性、錯誤容許\n\n### 系統規格估算\n\n- 寫入量：100 million 個網址 / 日\n\n- 每秒寫入量：100 million / 24 / 3600 = 1160\n\n- 讀取量：假設讀寫比為 10 : 1，每秒讀取量為 1160 * 10 = 11,600\n\n- 假設此服務會運作 10 年，總網址量為 100 million * 365 * 10 = 365 billion\n\n- 假設平均一個網址長度為 100 bytes\n\n- 10 年的規格上限為 365 billion * 100 bytes * 10 years = 365 TB\n\n## 步驟二：high-level 架構\n\n### API Endpoints\n\n1. URL shortening\n\nREST API 範例如：\n\n```\nPOST api/v1/data/shorten\n\n- request parameter: {longUrl: longURLString}\n- return shortURL\n```\n\n假設縮短後的網址格式如：\n```\nwww.tinyurl.com/{hashValue}\n```\n\n我們需設計一 hash 函數來將長網址對應成短網址，需符合兩條件\n\n- 每一長網址對應唯一的短網址字串（即上面的 hashValue）\n- 每一 hashValue 可對應回去長網址\n\n2. URL redirecting\n\nREST API 範例如：\n\n```\nGET api/v1/shortUrl\n\n- Return longURL for HTTP redirection\n```\n\n重導向流程可見下圖\n\n![](assets/redirect.png)\n\n301 vs 302 重導向\n\n301 為永久轉址，302 為暫時轉址，如果想減少伺服器負擔，用 301，因為能 cache 在瀏覽器端，不會再向短網址伺服器發送請求；但如果 analytics 很重要，用 302，因為有經過短網址伺服器才能追蹤流量、分析行銷成效等等\n\n## 步驟三：深入探討\n\n### 資料結構\n\n![](assets/ds.png)\n\n### hash 函數（for URL shortening）\n\n選擇合適的 hash 函數前，我們需要先估算 hashValue 的最小長度，每一 hashValue 裡的字元可為 [0-9, a-z, A-Z]，有 10 + 26 + 26 = 62 個選項，因上限的總網址量為 365 billion 筆，hashValue 的最小長度為 minimum n that can make 62^n ≥ 365 billion，可算出 n = 7 時可符合條件，因此 hashValue 的最小長度為 7\n\n兩種設計 hash 函數的方法：\n\n1. 使用知名的 hash functions + 碰撞處理\n2. Base 62 conversion\n\n#### 知名 hash functions + 碰撞處理\n\n![](assets/hash_with_collision.png)\n\n用知名的 hash 演算法，如 CRC32、MD5、SHA-1...，缺點為 hash 出來的字串太長，以及還需要向資料庫確認是否有碰撞，會降低效能，一個提高檢查效率的改進方式為應用 Bloom filter（見下方備註），雖有可能產生 false positive，但在此應用情境下可容忍\n\n註：Bloom filter介紹\n\n(from wiki) Bloom filter is a space-efficient probabilistic data structure, that is used to test whether an element is a member of a set.\n\nBloom filter 說沒有該資料的話**一定**沒有，說有該資料的話**不一定**有（definitely no and probably yes）\n\n適用情境\n\n![](assets/bf.png)\n\n使用案例\n\n1. Database\n\n![](assets/bf_case1.png)\n\n2. CDN\n\nAkamai cdn 上有 75% 的網址只被訪問過一次，這種冷門的網址不需收錄進去 cdn 節省空間，也因此降低快取的負擔、提高 cache hit 機率\n\n![](assets/bf_case2.png)\n\n3. 惡意網址檢測\n\n![](assets/bf_case3.png)\n\n4. 弱密碼檢測\n\n![](assets/bf_case4.png)\n\n簡易範例\n\n![](assets/bf_example.png)\n\n將 input 經過多個 hash 函數後，如在對應的位置都為 1，則 probably yes，如有一個位置為 0，則 definitely no\n\n[Ref](https://www.youtube.com/watch?v=V3pzxngeLqw)\n\n#### Base 62 conversion\n\n![](assets/base62.png)\n\n先根據章節 7 的唯一 ID 生成器生出純數字 UUID 後，將之轉為 62 進位，如得到的 UUID 為 11,157，對應的 62 進位算法為：\n\n![](assets/base62_example.png)\n\n兩個方法的比較表\n\n![](assets/comparison.png)\n\n### URL 重導向（redirecting）\n\n![](assets/redirect_flow.png)\n\n## 步驟四：總結\n\n延伸可討論的點：\n\n- Rate limiter：避免惡意使用者灌爆服務，見第四章筆記\n\n- Web server scaling：因為此服務不需紀錄狀態，所以 web server 可輕易 auto-scale\n\n- Database scaling：Database replication and sharding\n\n- Analytics：結合分析工具來收集點擊量、何時點擊、轉化率等等商業面需要知道的數據，除了上述提到的讓流量經過短網址伺服器時收集，加入分析工具後也會讓網址變很長（UTM tracking），這時短網址服務就更重要了\n\n- Availability, consistency, and reliability，見第一章筆記"},{"fields":{"slug":"/placeholder/","title":"This Is a Placeholder File for Mdx"},"frontmatter":{"draft":true},"rawBody":"---\ntitle: This Is a Placeholder File for Mdx\ndraft: true\ntags:\n  - gatsby-theme-primer-wiki-placeholder\n---\n"}]}}}